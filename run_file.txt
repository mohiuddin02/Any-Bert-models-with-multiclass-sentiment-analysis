python run_classifier.py \
  --task_name=cola \
  --do_train=true \
  --do_eval=true \
  --data_dir=/home/dataset \
  --vocab_file=vocab.txt \
  --bert_config_file=bert_config.json \
  --init_checkpoint=bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=2e-5 \
  --num_train_epochs=3.0 \
  --output_dir=/home/mabdulq/lakehead/thesis/Others/Abhi/result \
  --save_checkpoints_steps 10000


python run_classifier.py \
  --task_name=cola \
  --do_predict=true \
  --data_dir=/home/dataset \
  --vocab_file=vocab.txt \
  --bert_config_file=bert_config.json \
  --init_checkpoint= /home/mabdulq/lakehead/thesis/Others/Abhi/result/model.ckpt-64 \
  --max_seq_length=128 \
  --output_dir=/home/mabdulq/lakehead/thesis/Others/Abhi/result \
